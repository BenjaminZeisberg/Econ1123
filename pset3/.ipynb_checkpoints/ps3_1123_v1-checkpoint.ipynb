{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Set 3: Household Expenditures and The Supplemental Nutrition Assistance Program<a name=\"cite_ref-1\"></a>[<sup>[1]</sup>](#cite_note-1)\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Spring 2023**<br/>\n",
    "**Instructor**: Gregory Bruich, Ph.D.\n",
    "\n",
    "- Posted on: 02/07/2023\n",
    "- Due at: 11:59pm on 02/14/2023 <3\n",
    "\n",
    "\n",
    "<a name=\"cite_note-1\"></a>[1.](#cite_ref-1) Background information is from Bruich (2014)\n",
    "\n",
    "<hr style=\"height:2.4pt\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suggested Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as sm\n",
    "from stargazer.stargazer import Stargazer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background\n",
    "\n",
    "The Food Stamp Program (now called the Supplemental Nutrition Assistance Program or SNAP) provides income to low-income households each month with the stated goal of helping them buy food. In April 2014, the average SNAP household consisted of just over two people and received $256 in benefits per month. SNAP benefits are restricted in that they can only be used to pay for certain food items purchased at retailers that have applied for and received authorization to\n",
    "participate in the program from the U.S. Department of Agriculture. Excluded items include alcohol, hot foods, and toiletries. \n",
    "\n",
    "There are two ways for a household to become eligible for SNAP. The first way is if all members of the household receive benefits through either the Supplemental Security Income program,<a name=\"cite_ref-2\"></a>[<sup>[2]</sup>](#cite_note-2) the Temporary Assistance for Needy Families program, or a county general assistance program. The second way is if household income and assets are below certain thresholds. Income and assets are measured the month prior to applying for benefits and are re-assessed at periodic intervals (typically 6 months). In addition, there are minimum work requirements (20 hours per week) for non-disabled adults between 18 and 50 years old without children. SNAP benefits may only be received by adults who do not meet this work requirement for three months out of the previous three years. Beneficiaries can often substitute work training or volunteering for the work\n",
    "requirement.\n",
    "\n",
    "Table 1 describes the variables included in the stata dataset `snap.dta`. The dataset is an extract\n",
    "from the National Household Food Acquisition and Purchase Survey (FoodAPS) from the U.S. Department of Agriculture (USDA). The sample is restricted to households receiving SNAP benefits. Survey respondents kept track of all food items purchased over a 24 hour period.\n",
    "\n",
    "The survey responses were merged with administrative data from the SNAP program, allowing us to measure the exact number of days since the household received its SNAP benefits. Spending and days since receipt of SNAP will be the main variables we utilize in this problem set, although we will also control for various other household level variables (e.g., the number of people in the household, whether the household owns a vehicle, whether the primary respondent has a high school education).\n",
    "\n",
    "<a name=\"cite_note-2\"></a>[2.](#cite_ref-2) An exception is that in California, Supplemental Security Income payments have included an additional cash amount for food stamp benefits since 1974. Therefore, individuals in California who receive Supplemental Security Income cannot also receive SNAP benefits separately.\n",
    "\n",
    "\n",
    "<hr style=\"height:2.4pt\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "**File**: `snap.dta`\n",
    "\n",
    "The data consist of $n=1215$ households from National Household Food Acquisition and Purchase Survey (FoodAPS) from the U.S. Department of Agriculture (USDA). All households are SNAP recipients.\n",
    "\n",
    "**Table 1: Definitions of Selected Variables in `snap.dta`**\n",
    "\n",
    "| Variable          | Description                                                              | N     | Mean   |\n",
    "| ----------------- | ------------------------------------------------------------------------ | ----- | ------ |\n",
    "| (1)               | (2)                                                                      | (3)   | (4)    |\n",
    "|                   |                                                                          |       |        |\n",
    "| `hhnum`           | 6-digit unique identifier for each household                             | 1,215 | n/a    |\n",
    "| `spending`        | Total amount spent ($) on both food away from home and food at home      | 1,215 | $21.80 |\n",
    "| `days`            | days since snap last received                                            | 1,215 | 14.01  |\n",
    "| `week1`           | 1st week of SNAP benefit month                                           | 1,215 | 0.321  |\n",
    "| `week2`           | 2nd week of SNAP benefit month                                           | 1,215 | 0.233  |\n",
    "| `week3`           | 3rd week of SNAP benefit month                                           | 1,215 | 0.230  |\n",
    "| `week4`           | 4th week of SNAP benefit month                                           | 1,215 | 0.216  |\n",
    "| `anyvehicle`      | whether anybody in household owns or leases a vehicle (y/n)              | 1,215 | 0.724  |\n",
    "| `hhsize`          | number of people at residence, excluding guests                          | 1,215 | 3.420  |\n",
    "| `primstoretime_d` | driving time, in minutes, between residence and primary food store       | 1,215 | 8.512  |\n",
    "| `white`           | Primary respondent is White                                              | 1,215 | 0.645  |\n",
    "| `black`           | Primary respondent is Black                                              | 1,215 | 0.207  |\n",
    "| `asian`           | Primary respondent is Asian or Native Hawaiian or Other Pacific Islander | 1,215 | 0.0156 |\n",
    "| `hispanic`        | Primary respondent is Hispanic                                           | 1,215 | 0.246  |\n",
    "| `highschool`      | Primary respondent has high school education                             | 1,215 | 0.720  |\n",
    "\n",
    "*Notes:* Table defines the variables from the FoodAPS data.\n",
    "\n",
    "\n",
    "<hr style=\"height:2.4pt\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hhnum</th>\n",
       "      <th>spending</th>\n",
       "      <th>snap_amount</th>\n",
       "      <th>days</th>\n",
       "      <th>week1</th>\n",
       "      <th>week2</th>\n",
       "      <th>week3</th>\n",
       "      <th>week4</th>\n",
       "      <th>anyvehicle</th>\n",
       "      <th>hhsize</th>\n",
       "      <th>primstoretime_d</th>\n",
       "      <th>white</th>\n",
       "      <th>black</th>\n",
       "      <th>asian</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>highschool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100012</td>\n",
       "      <td>5.520000</td>\n",
       "      <td>125.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2.37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100028</td>\n",
       "      <td>23.620001</td>\n",
       "      <td>725.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4.23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100040</td>\n",
       "      <td>22.010000</td>\n",
       "      <td>225.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100069</td>\n",
       "      <td>59.750000</td>\n",
       "      <td>175.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100076</td>\n",
       "      <td>30.650000</td>\n",
       "      <td>325.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hhnum   spending  snap_amount  days  week1  week2  week3  week4  \\\n",
       "0  100012   5.520000        125.0    27      0      0      0      1   \n",
       "1  100028  23.620001        725.0    17      0      0      1      0   \n",
       "2  100040  22.010000        225.0     6      1      0      0      0   \n",
       "3  100069  59.750000        175.0    17      0      0      1      0   \n",
       "4  100076  30.650000        325.0    27      0      0      0      1   \n",
       "\n",
       "   anyvehicle  hhsize  primstoretime_d  white  black  asian  hispanic  \\\n",
       "0           1       5             2.37      1      0      0         0   \n",
       "1           1       7             4.23      1      0      0         0   \n",
       "2           1       2             5.72      0      0      0         1   \n",
       "3           1       4             5.15      0      0      0         0   \n",
       "4           1       4             8.75      1      0      0         0   \n",
       "\n",
       "   highschool  \n",
       "0           1  \n",
       "1           0  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dataset into a pandas dataframe\n",
    "snap = pd.read_stata(\"snap.dta\")\n",
    "\n",
    "# Display first 5 rows of data\n",
    "snap.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2.4pt\">\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Please submit your Problem Set on Canvas. Your submission should include two files:\n",
    "1. This notebook as a `.ipynb` file with your code and answers to questions\n",
    "2. A `.pdf` version of this notebook. TODO: Provide general instructions on converting `.ipynb` to `pdf`\n",
    "\n",
    "<hr style=\"height:2.4pt\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "*Note: Short answers should be very succinct. Show your work and intuition clearly: credit is given for explanations and not just having the correct answer*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1\n",
    "\n",
    "Estimate the following regressions and generate a table of the results using `stargazer`. Report appropriate standard errors for each regression, and\n",
    "explain how you decided which standard errors to use.\n",
    "\n",
    "You will have to generate new variables: the square of `days`, natural log of `spending` and\n",
    "household size (`hhsize`), as well as the interaction terms `week2` × `anyvehicle`, `week3` ×\n",
    "`anyvehicle`, and `week4` × `anyvehicle`. See Table 2a and Table 2b for more guidance.\n",
    "\n",
    "- a) Column 1: Regress `spending` in dollars on `days`, the square of `days`, the natural log of `hhsize`, the variable `highschool`, and the variable `anyvehicle`. In Greek:\n",
    "$$Spending_i = \\alpha_0 + \\alpha_1days_i + \\alpha_2log(hhsize_i) + \\alpha_4highschool_i + \\alpha_5Vehicle_i + u_i$$\n",
    "\n",
    "- b) Column 2: Regress the natural log of `spending` on `days`, the square of `days`, the natural log of `hhsize`, the variable `highschool`, and the variable `anyvehicle`. In Greek:\n",
    "$$log(Spending_i) = \\alpha_0 + \\alpha_1days_i + \\alpha_2log(hhsize_i) + \\alpha_4highschool_i + \\alpha_5Vehicle_i + u_i$$\n",
    "\n",
    "- c) Column 3: Regress the natural log of `spending` on the dummy variables `week2`, `week3`, and `week4`. Estimate this regression over the subset of observations **for whom `anyvehicle` equals 1**. In Greek:\n",
    "$$log(Spending_i) = \\alpha_0 + \\alpha_1Week2_i + \\alpha_2Week3_i + \\alpha_3Week4_i + u_i$$\n",
    "\n",
    "d. Column 4: Regress the natural log of `spending` on the dummy variables `week2`, `week3`, and `week4`. Estimate this regression over the subset of observations **for whom `anyvehicle` equals 0**. In Greek:\n",
    "$$log(Spending_i) = \\alpha_0 + \\alpha_1Week2_i + \\alpha_2Week3_i + \\alpha_3Week4_i + u_i$$\n",
    "\n",
    "e. Column 5: Regress the natural log of `spending` on the dummy variables `week2`, `week3`, `week4`, the variable `anyvehicle`, and new variables that equal `week2` × `anyvehicle`, `week3` × `anyvehicle`, and `week4` × `anyvehicle`. Estimate this regression over the full sample. In Greek:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "f(x)= & \\alpha_0 + \\alpha_1Week2_i + \\alpha_2Week3_i + \\alpha_3Week4_i + \\alpha_4 Vehicle_i + \\alpha_5 Week2_i \\times Vehicle_i\\\\\n",
    "& \\alpha_6 Week3_i \\times Vehicle_i + \\alpha_7 Week4_i \\times Vehicle_i + u_i\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here\n",
    "reg = sm.ols()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2.4pt\">\n",
    "\n",
    "### 2\n",
    "\n",
    "The number of observations in **Column 1** is greater than in **Column 2**. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[Your Answer Here]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2.4pt\">\n",
    "\n",
    "### 3\n",
    "Interpret the coefficient on log household size \n",
    "- (i) in column 1 and \n",
    "- (ii) in column 2\n",
    "\n",
    "in words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[Your Answer Here]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2.4pt\">\n",
    "\n",
    "### 4\n",
    "Use the regression in column 2 of your table to do the following:\n",
    "- a) Calculate the predicted effect of increasing days from $days = 1$ to $days = 2$\n",
    "- b) Calculate the standard error of the predicted effect by hand. Does your regression output table have all the information needed to calculate this standard error? Explain why or why not. (You can check your answer using `lincom`).\n",
    "- c) Calculate a 95% confidence interval for your predicted effect by hand. (You can check your answer using lincom).\n",
    "\n",
    "Note: you may use Stata/R (or a calculator) to help with your calculations in (b) and (c), but you should write out the formula you use with the appropriate values plugged in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[Your Answer Here]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2.4pt\">\n",
    "\n",
    "### 5\n",
    "\n",
    "This question has to do with the regressions in columns 3, 4, and 5 of your table.\n",
    "- a) Using the regression in column 4, interpret the coefficients on `week2`, `week3`, `week4` in words.\n",
    "- b) Using the regression in column 5, interpret the coefficients on `week2`, `week3`, `week4` in words. How do these coefficients compare with the coefficients you reported in column 4?\n",
    "- c) The “fully interacted regression” in column 5 provides exactly the same information as the regressions reported in column 4 and column 3. To see this, show that the sum of the coefficient on `week2` and `week2` × `anyvehicle` in column 5 exactly equals the coefficient on `week2` in column 3.\n",
    "- d) What do you think is an advantage of estimating the regressions separately as in columns 3 and 4? What do you think is an advantage to estimating the fully interacted regression as in column 5?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[Your Answer Here]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2.4pt\">\n",
    "\n",
    "### 6\n",
    "\n",
    "Using the regression in column 5, can you reject the null hypothesis the coefficients on `week2` × `anyvehicle`, `week3` × `anyvehicle`, and `week4` × `anyvehicle` are jointly zero?\n",
    "- a) Report your *F* statistic, its *p*-value, the 5% critical value for the test, and number of restrictions for this test.\n",
    "- b) Does the conclusion you draw from the 𝐹 test match the conclusion you would draw from *t*-tests of the significance of the coefficients individually? Explain.\n",
    "- c) Give a qualitative interpretation of what the null hypothesis from the previous question means in words. This is a thinking question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[Your Answer Here]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2.4pt\">\n",
    "\n",
    "### 7\n",
    "Suppose a policy maker is considering whether to fund a program that would make vehicles (zip cars) available to families receiving SNAP benefits. The policy maker would like to know if this program would increase spending on food. As we have discussed, policy questions like this are fundamentally “if-then” causal questions. Do you think that the coefficient on `anyvehicle` in column 1 measures the causal effect that the policy maker would want to know? If the coefficient does not measure the causal effect of interest, is the estimated coefficient too big or too small?\n",
    "\n",
    "Hint: provide an example of an omitted variable, then use the omitted variable bias formula and use your knowledge of the world to infer the signs of the inputs to the formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[Your Answer Here]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2.4pt\">\n",
    "\n",
    "### Sample Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adds another column to a dataframe storing the squares of values in the original\n",
    "```python\n",
    "# Note: not using simpler method np.square() due to\n",
    "# integer overflow\n",
    "snap[“x_squared”] = snap.x.astype(int) ** 2\n",
    "```\n",
    "\n",
    "Adds another column to a dataframe storing the natural log of values in the original, replacing infinite values with NaNs.\n",
    "```python\n",
    "snap[“log_x”] = np.log(snap.x).replace(-float(“inf”),\n",
    "np.nan)\n",
    "```\n",
    "\n",
    "Shows how to estimate an ordinary least squares regression with heteroskedasticity robust standard errors. Notice we specify that we wish to drop rows with missing data.\n",
    "```python\n",
    "mod = sm.ols(\n",
    "    “yvar ~ xvar1 + xvar2 + xvar3”,\n",
    "    data=snap,\n",
    "    missing=”drop”\n",
    ")\n",
    "res = mod.fit(cov_type=”HC2”)\n",
    "```\n",
    "\n",
    "Create a new dataframe that is a subset of the rows of the original where the xvar is equal to 5.\n",
    "```python\n",
    "five_df = snap.loc[snap.xvar == 5]\n",
    "```\n",
    "\n",
    "These lines show how to make a regression table with three columns, corresponding to\n",
    "- A regression of some variable yvar1 on xvar1, xvar2, and xvar3\n",
    "- A second regression of yvar1 on just xvar1 and xvar2\n",
    "- A third regression with a different dependent variable regressing yvar2 on xvar2 and xvar3\n",
    "Note we have to label the columns manually here. Also note we add an extra row to the bottom of the table and manually add entries\n",
    "```python\n",
    "# Estimate Regressions:\n",
    "mod1 = sm.ols(\n",
    "    “yvar1 ~ xvar1 + xvar2 + xvar3”,\n",
    "    data=health\n",
    ")\n",
    "res1 = mod.fit(cov_type=”HC2”)\n",
    "\n",
    "mod2 = sm.ols(\n",
    "    “yvar1 ~ xvar1 + xvar2”,\n",
    "    data=health\n",
    ")\n",
    "res2 = mod.fit(cov_type=”HC2”)\n",
    "\n",
    "mod3 = sm.ols(\n",
    "    “yvar2 ~ xvar2 + xvar3”,\n",
    "    data=health\n",
    ")\n",
    "res3 = mod.fit(cov_type=”HC2”)\n",
    "\n",
    "# Create Table\n",
    "table = Stargazer(models)\n",
    "\n",
    "# Label columns\n",
    "# This list of 1s should be the same length as the\n",
    "# number of columns\n",
    "table.custom_columns([“yvar1”, “yvar1”, “yvar2”],\n",
    "seperators=[1, 1, 1])\n",
    "\n",
    "# Add custom row at bottom of table:\n",
    "table.add_line(“Sample:”, [“hello”, “hi”, “hey”])\n",
    "\n",
    "# Display table\n",
    "table\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "Shows how to access the coefficients and covariance matrix of regression result\n",
    "```python\n",
    "# Access coefficient on xvar1\n",
    "alpha_1 = res.params.xvar1\n",
    "# Access covariance matrix of result\n",
    "cov_matrix = res.cov_params()\n",
    "# Access covariance between xvar1 and xvar2:\n",
    "cov_x1_x2 = cov_matrix.xvar1.xvar2\n",
    "```\n",
    "\n",
    "\n",
    "Shows how to run an F test that variables xvar1, xvar2, and xvar3 are not all 0 on a regression result\n",
    "```python\n",
    "# Run Test\n",
    "test_results = res.wald_test([\n",
    "    “xvar1 = 0”,\n",
    "    “xvar2 = 0”,\n",
    "    “xvar3 = 0”,\n",
    "], scalar=True, use_f=True)\n",
    "\n",
    "# collect f statistic\n",
    "f_stat = test_results.fvalue\n",
    "\n",
    "#collect degrees of freedom\n",
    "df = test_results.df_num\n",
    "Calculate true p-value\n",
    "true_p = 1 – stats.chi2.cdf(fstat * df, df)\n",
    "\n",
    "#Calculate critical value:\n",
    "# note we use 10^10 rather than infinity due to function\n",
    "constraints\n",
    "INF = 10 ** 10\n",
    "crit_val = stats.f.ppf(.95, df, INF)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "79e5ed05f4768318b64dcf4024aadef9daee7381e42285f5aa40ea96b6adb5f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
